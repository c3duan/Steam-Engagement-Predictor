{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import os\n",
    "import math\n",
    "import statistics\n",
    "import sklearn\n",
    "import scipy.spatial\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notebook_path = os.path.abspath(\"Similarity_Based_Collaborative_Filtering.ipynb\")\n",
    "users_items_file_path = os.path.join(os.path.dirname(notebook_path), \"data/australian_users_items.json\")\n",
    "items_file_path = os.path.join(os.path.dirname(notebook_path), \"data/items_meta_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_items = []\n",
    "with open(users_items_file_path, 'r') as data:\n",
    "    for line in data:\n",
    "        users_items.append(ast.literal_eval(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(items_file_path, 'r') as data:\n",
    "    games_dict = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "playtimesPerItem = defaultdict(dict)\n",
    "playtimesPerUser = defaultdict(dict)\n",
    "itemNames = defaultdict(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for game in games_dict:\n",
    "    if 'owners' in games_dict[game]:\n",
    "        usersPerItem[game] = set(games_dict[game]['owners'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for user in users_items:\n",
    "    itemsPerUser[user['user_id']] = [item['item_id'] for item in user['items']]\n",
    "    playtimesPerUser[user['user_id']] = dict((item['item_id'], item['playtime_forever']) for item in user['items'])    \n",
    "    for item in user['items']:\n",
    "        itemNames[item['item_id']] = item['item_name']\n",
    "        playtimesPerItem[item['item_id']][user['user_id']] = item['playtime_forever']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = list(itemsPerUser.keys())\n",
    "items = list(usersPerItem.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity-Based Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isEmpty(game_a_id, game_b_id):\n",
    "    return len(usersPerItem[game_a_id]) == 0 or len(usersPerItem[game_b_id]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mostSimilar(game_a_id, sim):\n",
    "    similarities = []\n",
    "    for game_b_id in games_dict:\n",
    "        if game_b_id == game_a_id: continue\n",
    "        similarity = sim(game_a_id, game_b_id)\n",
    "        similarities.append((similarity, game_b_id))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mostSimilarNames(similarities):\n",
    "    return [itemNames[sim[1]] for sim in similarities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a generic implementation of the Jaccard similarity between two items: we find the union and intersection between their owners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard(game_a_id, game_b_id):\n",
    "    if isEmpty(game_a_id, game_b_id):\n",
    "        return 0\n",
    "    \n",
    "    owners_a = usersPerItem[game_a_id]\n",
    "    owners_b = usersPerItem[game_b_id]\n",
    "    \n",
    "    intersect_owners = owners_a.intersection(owners_b)\n",
    "    union_owners = owners_a.union(owners_b)\n",
    "    \n",
    "    return len(intersect_owners) / len(union_owners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mostSimilarJaccardFast(game_a_id):\n",
    "    similarities = []\n",
    "    users = usersPerItem[game_a_id]\n",
    "    candidateItems = set()\n",
    "    for user_id in users:\n",
    "        candidateItems = candidateItems.union(itemsPerUser[user_id])\n",
    "    for game_b_id in candidateItems:\n",
    "        if game_b_id == game_a_id: continue\n",
    "        sim = jaccard(game_a_id, game_b_id)\n",
    "        similarities.append((sim, game_b_id))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Half-Life: Blue Shift',\n",
       " 'Half-Life: Opposing Force',\n",
       " 'Team Fortress Classic',\n",
       " 'Half-Life: Source',\n",
       " 'Half-Life 2: Episode Two',\n",
       " 'Half-Life Deathmatch: Source',\n",
       " 'Half-Life 2: Episode One',\n",
       " 'Half-Life 2: Deathmatch',\n",
       " 'Half-Life 2',\n",
       " 'Half-Life 2: Lost Coast']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilarNames(mostSimilar('70', jaccard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Half-Life: Blue Shift',\n",
       " 'Half-Life: Opposing Force',\n",
       " 'Team Fortress Classic',\n",
       " 'Half-Life: Source',\n",
       " 'Half-Life 2: Episode Two',\n",
       " 'Half-Life Deathmatch: Source',\n",
       " 'Half-Life 2: Episode One',\n",
       " 'Half-Life 2: Deathmatch',\n",
       " 'Half-Life 2',\n",
       " 'Half-Life 2: Lost Coast']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilarNames(mostSimilarJaccardFast('70'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mark a item that is purchased and played (playtime > 0) **1**\n",
    "- Mark a item that is purchased but not played (playtime = 0) **-1**\n",
    "- Mark a item that is not purchased **0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def markOpinion(playtime):\n",
    "    return 1 if playtime > 0 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(game_a_id, game_b_id):\n",
    "    owners_a = usersPerItem[game_a_id]\n",
    "    owners_b = usersPerItem[game_b_id]\n",
    "    \n",
    "    counter_a = dict((x, markOpinion(playtimesPerUser[x][game_a_id])) for x in owners_a)\n",
    "    counter_b = dict((x, markOpinion(playtimesPerUser[x][game_b_id])) for x in owners_b)\n",
    "    \n",
    "    owners = owners_a.union(owners_b)\n",
    "    \n",
    "    return counter_a, counter_b, owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine(game_a_id, game_b_id):\n",
    "    if isEmpty(game_a_id, game_b_id):\n",
    "        return 0\n",
    "    \n",
    "    counter_a, counter_b, terms = count(game_a_id, game_b_id)\n",
    "    magA = np.array([[counter_a.get(k, 0) for k in terms]])\n",
    "    magB = np.array([[counter_b.get(k, 0) for k in terms]])\n",
    "    \n",
    "    return cosine_similarity(magA, magB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Half-Life 2',\n",
       " 'Team Fortress Classic',\n",
       " 'Portal',\n",
       " 'Portal 2',\n",
       " \"Garry's Mod\",\n",
       " 'Counter-Strike',\n",
       " 'Half-Life 2: Episode One',\n",
       " 'Counter-Strike: Source',\n",
       " 'Left 4 Dead 2',\n",
       " 'Half-Life: Opposing Force']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilarNames(mostSimilar('70', cosine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mark a item that is purchased and played (playtime > 0) with the value of its **playtime**\n",
    "- Mark a item that is purchased but not played (playtime = 0) **-1**\n",
    "- Mark a item that is not purchased **0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def markValue(playtime):\n",
    "    return playtime if playtime > 0 else -1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(game_a_id, game_b_id):\n",
    "    owners_a = usersPerItem[game_a_id]\n",
    "    owners_b = usersPerItem[game_b_id]\n",
    "    \n",
    "    counter_a = dict((x, playtimesPerUser[x][game_a_id]) for x in owners_a)\n",
    "    counter_b = dict((x, playtimesPerUser[x][game_b_id]) for x in owners_b)\n",
    "    \n",
    "    owners = owners_a.union(owners_b)\n",
    "\n",
    "    return counter_a, counter_b, owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pearson(game_a_id, game_b_id):\n",
    "    if isEmpty(game_a_id, game_b_id):\n",
    "        return 0\n",
    "            \n",
    "    counter_a, counter_b, terms = count(game_a_id, game_b_id)\n",
    "    magA = np.array([counter_a.get(k, 0) for k in terms])\n",
    "    magB = np.array([counter_b.get(k, 0) for k in terms])\n",
    "    return np.corrcoef(magA, magB)[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Arnold/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:2530: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/Arnold/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:2531: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BRAINPIPE: A Plunge to Unhumanity',\n",
       " 'Mini Motor Racing EVO',\n",
       " 'Violett',\n",
       " 'The Plan',\n",
       " 'Procyon',\n",
       " 'The Forgotten Ones',\n",
       " 'Our Love Will Grow',\n",
       " 'Road Madness',\n",
       " 'Millie',\n",
       " 'Little Racers STREET']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mostSimilarNames(mostSimilar('70', pearson))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Playtime Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the similarity-based recommender we developed above to make predictions about user's playtime. Although this is not an example of machine learning, it is a simple heuristic that can be used to estimate a user's future playtime based on their playtime in the past.\n",
    "\n",
    "Specifically, a user's playtime for an item is assumed to be a weighted sum of their previous playtime, weighted by how similar the query item is to each of their previous purchases.\n",
    "\n",
    "Use median playtime and mean playtime as bench mark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "def update_progress(progress):\n",
    "    bar_length = 40\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "        \n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictPlaytime(user, game_a, sim, default):\n",
    "    playtimes = []\n",
    "    similarities = []\n",
    "    for game_b in itemsPerUser[user]:\n",
    "        if game_b == game_a: continue\n",
    "        playtimes.append(playtimesPerUser[user][game_b])\n",
    "        similarities.append(sim(game_a, game_b))\n",
    "        \n",
    "    if (sum(similarities) > 0):\n",
    "        weightedPlaytime = [(x*y) for x,y in zip(playtimes, similarities)]\n",
    "        return sum(weightedPlaytime) / sum(similarities)\n",
    "    else:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPlaytime(users_items):\n",
    "    playtimes = []\n",
    "    for user in users_items:\n",
    "        for item in user['items']:\n",
    "            playtimes.append(item['playtime_forever'])\n",
    "            \n",
    "    return playtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "playtimes = getPlaytime(users_items)\n",
    "meanPlaytime = sum(playtimes) / len(playtimes)\n",
    "medianPlaytime = statistics.median(playtimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def markBinaryLabel(playtime, threshold):\n",
    "    return 1 if playtime >= threshold else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPairsAndLabels(users_items):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    for user in users_items:\n",
    "        for item in user['items']:\n",
    "            pairs.append((user['user_id'], item['item_id']))\n",
    "            labels.append(item['playtime_forever'])\n",
    "    return pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs, labels = getPairsAndLabels(users_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    differences = [1 if (x == y) else 0 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_train, pairs_test, labels_train, labels_test = train_test_split(pairs, labels, test_size = 0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meanPredictions = [markBinaryLabel(meanPlaytime, games_dict[p[1]]['median_playtime']) for p in pairs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medianPredictions = [markBinaryLabel(medianPlaytime, games_dict[p[1]]['median_playtime']) for p in pairs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computePredictions(sim, default):\n",
    "    predictions = []\n",
    "    num = len(pairs_test)\n",
    "    for index, pair in enumerate(pairs_test):\n",
    "        predictions.append(predictPlaytime(pair[0], pair[1], sim, default))\n",
    "        update_progress(index / num)\n",
    "    update_progress(1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_binary_labels = [markBinaryLabel(x, games_dict[p[1]]['median_playtime']) for x, p in zip(labels_test, pairs_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [########################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "jaccardMedianPredictions = computePredictions(jaccard, medianPlaytime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3953488372093023"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy([markBinaryLabel(x, games_dict[p[1]]['median_playtime']) for x, p in zip(jaccardMedianPredictions, pairs_test)], test_binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [########################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "cosineMedianPredictions = computePredictions(cosine, medianPlaytime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3953488372093023"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy([markBinaryLabel(x, games_dict[p[1]]['median_playtime']) for x, p in zip(cosineMedianPredictions, pairs_test)], test_binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [########################################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "pearsonMedianPredictions = computePredictions(pearson, medianPlaytime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5891472868217055"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy([markBinaryLabel(x, games_dict[p[1]]['median_playtime']) for x, p in zip(pearsonMedianPredictions, pairs_test)], test_binary_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
