{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sy\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "import copy \n",
    "import itertools\n",
    "from tqdm import *\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from ipynb.fs.full.Random_Sample_Mapper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = os.path.abspath(\"BPR_OPT_Binary_Model.ipynb\")\n",
    "users_items_file_path = os.path.join(os.path.dirname(notebook_path), \"data/australian_users_items.json\")\n",
    "items_file_path = os.path.join(os.path.dirname(notebook_path), \"data/items_meta_data.json\")\n",
    "users_meta_data_file_path = os.path.join(os.path.dirname(notebook_path), \"data/users_meta_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items = []\n",
    "with open(users_items_file_path, 'r') as data:\n",
    "    for line in data:\n",
    "        users_items.append(ast.literal_eval(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(items_file_path, 'r') as data:\n",
    "    games_dict = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(users_meta_data_file_path, 'r') as file:\n",
    "    users_meta_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "playtimesPerItem = defaultdict(dict)\n",
    "playtimesPerUser = defaultdict(dict)\n",
    "itemNames = defaultdict(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_usersPerItem = defaultdict(set)\n",
    "train_itemsPerUser = defaultdict(set)\n",
    "test_usersPerItem = defaultdict(set)\n",
    "test_itemsPerUser = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for game in games_dict:\n",
    "    if 'owners' in games_dict[game]:\n",
    "        usersPerItem[game] = set(games_dict[game]['owners'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users_items:\n",
    "    u_id = user['user_id']\n",
    "    items = [item['item_id'] for item in user['items']]\n",
    "    itemsPerUser[u_id] = items\n",
    "    \n",
    "    items_train, items_test = train_test_split(items, test_size = 0.20)\n",
    "    train_itemsPerUser[u_id] = items_train\n",
    "    test_itemsPerUser[u_id] = items_test\n",
    "\n",
    "    playtimesPerUser[user['user_id']] = dict((item['item_id'], item['playtime_forever']) for item in user['items'])\n",
    "    for item in user['items']:\n",
    "        itemNames[item['item_id']] = item['item_name']\n",
    "        playtimesPerItem[item['item_id']][user['user_id']] = item['playtime_forever']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in train_itemsPerUser:\n",
    "    for item in train_itemsPerUser[user]:\n",
    "        train_usersPerItem[item].add(user)\n",
    "        \n",
    "    for item in test_itemsPerUser[user]:\n",
    "        test_usersPerItem[item].add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nUsers = len(itemsPerUser)\n",
    "nItems = len(usersPerItem)\n",
    "users = list(itemsPerUser.keys())\n",
    "items = list(usersPerItem.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_item_counts = dict((k, len(v)) for k, v in train_itemsPerUser.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_item_counts = dict((k, len(v)) for k, v in test_itemsPerUser.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datafile = 'data/train_sample_in.tsv'\n",
    "train_mapout1 = 'data/train_sample_map1.tsv'\n",
    "train_mapout2 = 'data/train_sample_map2.tsv'\n",
    "train_outfile = 'data/train_sample_out.tsv'\n",
    "\n",
    "f = open(train_datafile,'w')\n",
    "for u, its in train_itemsPerUser.items():\n",
    "    for i in its:\n",
    "        print(default_formatter(u,i), file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run two stages of mapreduce\n",
    "train_mapper = Mapper(train_user_item_counts)\n",
    "mapreduce(train_datafile, train_mapout1, mapper=train_mapper, reducer=reducer)\n",
    "mapreduce(train_datafile, train_mapout2, mapper=indicator_mapper)  # map the data again\n",
    "mapreduce([train_mapout1, train_mapout2], train_outfile, reducer=indicator_reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = []\n",
    "\n",
    "for u, its in test_itemsPerUser.items():\n",
    "    ii = list(train_itemsPerUser[u])\n",
    "    if len(ii) < 1: continue\n",
    "    for j in its:\n",
    "        ii = list(train_itemsPerUser[u])\n",
    "        if len(ii) < 1: continue\n",
    "        i = random.choice(ii)\n",
    "        test_sample.append((u, i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExternalSchedule(object):\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        \n",
    "    def generate_random_samples(self, size=None, rand=True):\n",
    "        f = open(self.filepath)\n",
    "        samples = [map(str, line.strip().split()) for line in f]\n",
    "        if rand:\n",
    "            random.shuffle(samples)  # important!\n",
    "        if size is None:\n",
    "            size = len(samples)\n",
    "        for u, i, j in samples[:size]:\n",
    "            yield u, i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ExternalSchedule(train_outfile)  # schedule is one-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(x, y):\n",
    "    return sum([a*b for a,b in zip(x,y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(u, i, j):\n",
    "    return u[1:len(u)-1], i[2:len(i)-2], j[1:len(j)-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_label(u, i, j):\n",
    "    c = Counter(itemsPerUser[u])\n",
    "    return c[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(sample):\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for u, i, j in sample:\n",
    "        predict = sigmoid(prediction(u, i, j))\n",
    "        predictions.append(predict)\n",
    "        label = binary_label(u, i, j)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return accuracy_score(labels, np.rint(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    #Numerically stable sigmoid function.\n",
    "    #Taken from: https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
    "    if x >= 0:\n",
    "        z = np.exp(-x)\n",
    "        return 1 / (1 + z)\n",
    "    else:\n",
    "        # if x is less than zero then z will be small, denom can't be\n",
    "        # zero because it's 1+z.\n",
    "        z = np.exp(x)\n",
    "        return z / (1 + z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple (Biase Only) Latent Factor Model with Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global itemBiases\n",
    "    itemBiases = dict(zip(items, theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "f(i, j) = \\beta_i - \\beta_j\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "p(i >_u j) = \\sigma(f(i, j))\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(u, item_i, item_j):\n",
    "    return itemBiases[item_i] - itemBiases[item_j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\text{BPR-OPT} := \\text{argmax} \\ln(\\sigma(\\beta_i - \\beta_j))\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\text{Cost Function}:= \\sum_{u,i,j} ln\\left( \\frac{1}{1 + e^{\\beta_j - \\beta_i}} \\right)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta):\n",
    "    unpack(theta)\n",
    "    cost = 0\n",
    "    sample = []\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for u, i, j in sampler.generate_random_samples():\n",
    "        u, i, j = trim(u, i ,j)\n",
    "        sample.append((u, i, j))\n",
    "        x = prediction(u, i, j)\n",
    "        predictions.append(sigmoid(x))\n",
    "        labels.append(binary_label(u, i, j))\n",
    "\n",
    "        cost += (1 - sigmoid(x))\n",
    "        \n",
    "    print(-cost)\n",
    "    print(accuracy_score(labels, np.rint(predictions)))\n",
    "    \n",
    "    return -cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial }{\\partial x} ln\\sigma(x) = \\frac{1}{1 + e^x} = \\sigma(-x)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial f}{\\partial \\beta_i} = \\frac{e^{\\beta_j - \\beta_i}}{1 + e^{\\beta_j - \\beta_i}} = \\frac{1}{1 + e^{\\beta_i - \\beta_j}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial f}{\\partial \\beta_j} = -\\frac{e^{\\beta_j - \\beta_i}}{1 + e^{\\beta_j - \\beta_i}} = -\\frac{1}{1 + e^{\\beta_i - \\beta_j}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta):\n",
    "    unpack(theta)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for u, i, j in sampler.generate_random_samples():\n",
    "        u, i, j = trim(u, i ,j)\n",
    "        x = prediction(u, i, j)\n",
    "        dbase = 1 / (1 + np.exp(x))\n",
    "        dItemBiases[i] += dbase\n",
    "        dItemBiases[j] -= dbase\n",
    "    dtheta = [dItemBiases[i] for i in items]\n",
    "    return np.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, f, d = sy.optimize.fmin_l_bfgs_b(cost, [0.0]*nItems, derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Latent Factor Model with Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple non-biased latent factor model that is wrapped into a binary function (sigmoid function) as a base line model, using popularity as the item's sole feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each user and item we now have a low dimensional descriptor (representing that user's preferences, and that item's properties), of dimension K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userGamma = {}\n",
    "itemGamma = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in itemsPerUser:\n",
    "    userGamma[u] = [random.random() * 0.1 - 0.05 for k in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in usersPerItem:\n",
    "    itemGamma[i] = [random.random() * 0.1 - 0.05 for k in range(K)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use another library in this example to perform gradient descent. This library requires that we pass it a \"flat\" parameter vector (theta) containing all of our parameters. This utility function just converts between a flat feature vector, and our model parameters, i.e., it \"unpacks\" theta into our offset and bias parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global itemBiases\n",
    "    global userGamma\n",
    "    global itemGamma\n",
    "    index = 0\n",
    "    itemBiases = dict(zip(items, theta[0:index + nItems]))\n",
    "    index += nItems\n",
    "    for u in users:\n",
    "        userGamma[u] = theta[index:index + K]\n",
    "        index += K\n",
    "    for i in items:\n",
    "        itemGamma[i] = theta[index:index + K]\n",
    "        index += K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "f(u, i, j) = \\gamma_u \\gamma_i + \\beta_i - (\\gamma_u \\gamma_j + \\beta_j)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "p(i >_u j) = \\sigma(f(u, i, j))\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item_i, item_j):\n",
    "    return inner(userGamma[user], itemGamma[item_i]) + itemBiases[item_i] - (inner(userGamma[user], itemGamma[item_j]) + itemBiases[item_j]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\text{BPR-OPT} := \\text{argmax} \\ln(\\sigma(\\gamma_u \\gamma_i + \\beta_i - (\\gamma_u \\gamma_j + \\beta_j)))\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\text{Cost Function}:= \\sum_{u,i,j} ln\\left( \\frac{1}{1 + e^{\\gamma_u \\gamma_j + \\beta_j - (\\gamma_u \\gamma_i + \\beta_i)}} \\right)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta):\n",
    "    unpack(theta)\n",
    "    cost = 0\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for u, i, j in sampler.generate_random_samples(rand=False):\n",
    "        u, i, j = trim(u, i ,j)\n",
    "        x = prediction(u, i, j)\n",
    "        predictions.append(sigmoid(x))\n",
    "        labels.append(binary_label(u, i, j))\n",
    "\n",
    "        cost += (1 / (1 + np.exp(x)))\n",
    "        \n",
    "    print('Current Cost: %s' % cost)\n",
    "    print('Current Accuracy: %s' % accuracy_score(labels, np.rint(predictions)))\n",
    "        \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial f}{\\partial \\gamma_{u,k}} = \\frac{(\\gamma_{i,k} - \\gamma_{j,k}) \\cdot e^{\\gamma_u \\gamma_j + \\beta_j - (\\gamma_u \\gamma_i + \\beta_i)}}{1 + e^{\\gamma_u \\gamma_j + \\beta_j - (\\gamma_u \\gamma_i + \\beta_i)}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial f}{\\partial \\gamma_{i,k}} = \\frac{\\gamma_{u,k} \\cdot e^{\\gamma_u \\gamma_j + \\beta_j - (\\gamma_u \\gamma_i + \\beta_i)}}{1 + e^{\\gamma_u \\gamma_j + \\beta_j - (\\gamma_u \\gamma_i + \\beta_i)}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial f}{\\partial \\gamma_{j,k}} = -\\frac{\\gamma_{u,k} \\cdot e^{\\gamma_u \\gamma_j + \\beta_j - (\\gamma_u \\gamma_i + \\beta_i)}}{1 + e^{\\gamma_u \\gamma_j + \\beta_j - (\\gamma_u \\gamma_i + \\beta_i)}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial f}{\\partial \\beta_i} = \\frac{e^{\\gamma_u \\gamma_j + \\beta_j - (\\gamma_u \\gamma_i + \\beta_i)}}{1 + e^{\\gamma_u \\gamma_j + \\beta_j - (\\gamma_u \\gamma_i + \\beta_i)}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\frac{\\partial f}{\\partial \\beta_j} = -\\frac{e^{\\gamma_u \\gamma_j + \\beta_j - (\\gamma_u \\gamma_i + \\beta_i)}}{1 + e^{\\gamma_u \\gamma_j + \\beta_j - (\\gamma_u \\gamma_i + \\beta_i)}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta):\n",
    "    unpack(theta)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    dUserGamma = {}\n",
    "    dItemGamma = {}\n",
    "    for u in users:\n",
    "        dUserGamma[u] = [0.0 for k in range(K)]\n",
    "    for i in items:\n",
    "        dItemGamma[i] = [0.0 for k in range(K)]\n",
    "    for u, i, j in sampler.generate_random_samples(rand=False):\n",
    "        u, i, j = trim(u, i ,j)\n",
    "        x = prediction(u, i ,j)\n",
    "        dbase = 1 / (1 + np.exp(x))\n",
    "        dItemBiases[i] += dbase\n",
    "        dItemBiases[j] -= dbase\n",
    "        for k in range(K):\n",
    "            dUserGamma[u][k] += (itemGamma[i][k] - itemGamma[j][k]) * dbase\n",
    "            dItemGamma_k = userGamma[u][k] * dbase\n",
    "            dItemGamma[i][k] += dItemGamma_k\n",
    "            dItemGamma[j][k] -= dItemGamma_k\n",
    "    dtheta = [dItemBiases[i] for i in items]\n",
    "    for u in users:\n",
    "        dtheta += dUserGamma[u]\n",
    "    for i in items:\n",
    "        dtheta += dItemGamma[i]\n",
    "    return np.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_res, f, d = sy.optimize.fmin_l_bfgs_b(cost, [0.0]*nItems + # Initialize beta\n",
    "                                [random.random() * 0.1 - 0.05 for k in range(K*(nUsers + nItems))], # Gamma\n",
    "                             derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpack(complete_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
